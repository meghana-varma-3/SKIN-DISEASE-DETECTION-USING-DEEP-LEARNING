{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8222f743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\megha\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\megha\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\megha\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "1/1 [==============================] - 1s 683ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Preprocess the image\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(75, 100))  # Adjust target size as needed\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.  # Normalize pixel values\n",
    "    return img_array\n",
    "\n",
    "# Step 2: Load the model\n",
    "model = load_model('trained_model.h5')\n",
    "\n",
    "# Step 3: Perform prediction\n",
    "img_path = r\"C:\\Users\\megha\\Desktop\\PRO\\sample_5_z\\Basal\\ba-1.jpg\"\n",
    "preprocessed_img = preprocess_image(img_path)\n",
    "predictions = model.predict(preprocessed_img)\n",
    "\n",
    "# Assuming you have a list or dictionary containing the class names\n",
    "\n",
    "class_names = ['NULL', 'Basal', 'Benign','Psoriasis','Warts']\n",
    "\n",
    "# Get the index of the predicted class\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "\n",
    "# Get the name of the predicted class\n",
    "predicted_class_name = class_names[predicted_class_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1174d31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13f2cc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Basal'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03b0f09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Preprocess the image\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(75, 100))  # Adjust target size as needed\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.  # Normalize pixel values\n",
    "    return img_array\n",
    "\n",
    "# Step 2: Load the model\n",
    "model = load_model('trained_model.h5')\n",
    "\n",
    "# Step 3: Perform prediction\n",
    "img_path = r\"C:\\Users\\megha\\Desktop\\PRO\\sample_5_z\\Benign\\be-1.jpg\"\n",
    "preprocessed_img = preprocess_image(img_path)\n",
    "predictions = model.predict(preprocessed_img)\n",
    "\n",
    "\n",
    "class_names = ['NULL', 'Basal', 'Benign','Psoriasis','Warts']\n",
    "\n",
    "# Get the index of the predicted class\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "\n",
    "# Get the name of the predicted class\n",
    "predicted_class_name = class_names[predicted_class_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d93d0c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00fa8ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Benign'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d5d8942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Preprocess the image\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(75, 100))  # Adjust target size as needed\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.  # Normalize pixel values\n",
    "    return img_array\n",
    "\n",
    "# Step 2: Load the model\n",
    "\n",
    "model = load_model('trained_model.h5')\n",
    "\n",
    "# Step 3: Perform prediction\n",
    "img_path = r\"C:\\Users\\megha\\Desktop\\PRO\\sample_5_z\\Psoriasis\\p-1.jpg\"\n",
    "preprocessed_img = preprocess_image(img_path)\n",
    "predictions = model.predict(preprocessed_img)\n",
    "\n",
    "# Assuming you have a list or dictionary containing the class names\n",
    "#class_names = ['Basal','Benign','Warts']\n",
    "#class_names = ['Melanoma', 'Basal', 'Benign','Warts']\n",
    "class_names = ['NULL', 'Basal', 'Benign','Psoriasis','Warts']\n",
    "\n",
    "# Get the index of the predicted class\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "\n",
    "# Get the name of the predicted class\n",
    "predicted_class_name = class_names[predicted_class_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a930cf25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0fad888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Psoriasis'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "719a580c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Preprocess the image\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(75, 100))  # Adjust target size as needed\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.  # Normalize pixel values\n",
    "    return img_array\n",
    "\n",
    "# Step 2: Load the model\n",
    "model = load_model('trained_model.h5')\n",
    "\n",
    "# Step 3: Perform prediction\n",
    "img_path = r\"C:\\Users\\megha\\Desktop\\PRO\\sample_5_z\\Warts\\w-1.jpg\"\n",
    "preprocessed_img = preprocess_image(img_path)\n",
    "predictions = model.predict(preprocessed_img)\n",
    "class_names = ['NULL', 'Basal', 'Benign','Psoriasis','Warts']\n",
    "\n",
    "# Get the index of the predicted class\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "\n",
    "# Get the name of the predicted class\n",
    "predicted_class_name = class_names[predicted_class_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88ed4bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a621cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Warts'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
